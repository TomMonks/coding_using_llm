---
format:
  revealjs: 
    theme: ["styles.scss"]
    footer: "<https://github.com/TomMonks/coding_using_llm>"
    preview-links: true
    height: 800
    width: 1250
    preload-iframes: true
    controls: true
    controls-layout: bottom-right
    revealjs-plugins:
     - fullscreen

---

# An introduction to prompt engineering for coding


<br>
<h3>Tom Monks <a href="https://orcid.org/0000-0003-2631-4481" aria-label="View ORCID record"><img src="images/orcid.png" alt="ORCID iD" style="width:32px; margin-left:15px; margin-right:6px; vertical-align:middle;"></a>0000-0003-2631-4481</h3>
<br>
<br>


## Today

* The future üîÆü§©üò¨
* LLM contexts, context lengths and tokens
* Hallucination üòµ‚Äçüí´ vs. data contamination ü§¢ vs. understanding ü§î
* Retrieval Augmented Generation (RAG)
* AI in your IDE versus a ChatBot
* Applied examples and exercises

## Exercises for fun

* One and few-shot. 
  * Coding a basic boostrap
  * Adding PEP257 or numpy style docstrings

* System prompt
  * defensive programming 
  * units testing

> All exercises were designed for my Python class üêç. But please use what you like!


## The future

![Kwa et al. (2025). Measuring AI Ability to Complete Long Tasks. arxiv. https://arxiv.org/abs/2503.14499](images/kwa_et_al.png)


## Context and tokens

```text
Given five positive integers, find the minimum and maximum values that 
can be calculated by summing exactly four of the five integers. 
Print the respective minimum and maximum values.
```

Token visualiser: [https://lunary.ai/deepseek-tokenizer](https://lunary.ai/deepseek-tokenizer)

## Hallucination (1)

![](images/bard_halluc.png)


## Hallucination (2)

![](images/bard_astro_response.png)

## Other reasons for mistakes:

* **Data contamination**
  * Trained on public code - the good, the bad, and the ugly
  * **Side issue:** difficult to assess capablities due to the size and obscurity of training data (leakage).

* **LLM Understanding**
  * Have you been clear or ambigous?
  * Is the model capable of understanding?


## Retrieval Augmented Generation

Let's take a look at [Perplexity.AI](https://www.perplexity.ai/) to see RAG in action.

## AI code editors instead of Chatbots

![](images/cursor_IDE.png)


## Prompt Engineering for coding

The process of crafting effective inputs to elicit desired outputs from LLMs.

:::: {.columns}

::: {.column width="50%"}
![](images/prompt_engineer_1.jpg)
:::

::: {.column width="50%"}
![](images/prompt_engineer_2.jpg)
:::

::::

## Some simple principles

1. Provide examples where you can (so called one shot / few shot)
2. Don't ask AI to do too much in one go. Iteratively build code and context.
3. One topic per context. Keep it simple.
4. Be specific about what you want the code to output
5. For more complex code you are almost writing code in natural language. 
6. Reasoning models can be great, but aren't always needed for simple coding. 
7. You have to check the code is valid.
8. Consider using AI to improve the quality of the code you write yourself.
9. If it feels too easy then you might find its wrong!


## {#Exercises fullscreen=true}

<iframe class="stretch" data-src="exercises/exercises.html"></iframe>  -->

## {#Testing fullscreen=true}

<iframe class="stretch" data-src="exercises/testing_exercises.html"></iframe>  -->

## {#Search fullscreen=true}

<iframe class="stretch" data-src="exercises/search_task.html"></iframe>  -->

## {#Complex fullscreen=true}

<iframe class="stretch" data-src="exercises/simulation_models.html"></iframe>  -->

## Happy coding

::: {.column width="50%"}
![](images/prompt_engineer_1.jpg)
:::

::: {.column width="50%"}
![](images/prompt_engineer_2.jpg)
:::